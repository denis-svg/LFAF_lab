#+title: Lab2
#+PROPERTY: header-args:python   :session :results output :exports both :eval no-export
* Implementation of formal languages
- Course :: Formal Languages & Finite Automata
- Author :: Balan Artiom

* Theory
An instance of a *formal language* is a set of /words/ which are composed of /letters/.
The set of words can be defined in many ways:
- by simply enumerating all the valid elements (words)
- by defining an alphabet and a grammar

An *alphabet* is a set of letters.

A *grammar* is a set of rules that define how to form valid words from the alphabet.

A regular grammar is one in which all production rules in P are of one of the following forms:
- A → a
- A → aB
- A → ε
where A, B, S ∈ N are non-terminal symbols, a ∈ Σ is a terminal symbol,
and ε denotes the empty string, i.e. the string of length 0. S is called the start symbol.

[[https://en.wikipedia.org/wiki/Automata_theory][Automata]] can be used to recognize formal languages, for example described by grammars.
There are different [[https://en.wikipedia.org/wiki/Automata_theory#Types_of_automata][types of automata]] that can describe different types of languages.
For example:
- A finite automaton (NFA/DFA, state machine) can describe a regular grammar (type 3)
- A pushdown automaton (PDA) can describe a context-free grammar (type 2)

A DFA is equivalent in power to an NFA, even though NFA's are more flexible ([[https://en.wikipedia.org/wiki/Automata_theory#Hierarchy_in_terms_of_powers][Hierarchy in terms of powers]]).

- The conversion NFA -> DFA can be done using the [[https://en.wikipedia.org/wiki/Powerset_construction][powerset construction]].
- The conversion regular grammar -> NFA and viceversa is straightforward.
- The conversion Grammar -> DFA can't really be done directly,
  instead go through the steps: Grammar -> NFA -> DFA.
* Objectives
#+begin_src python :exports none
from src.grammar import *
from src.automata import *
#+end_src

- [X] Provide a function in your grammar type/class that could classify the grammar based on Chomsky hierarchy.
- [X] Implement conversion of a finite automaton to a regular grammar.
- [X] Determine whether your FA is deterministic or non-deterministic.
- [X] Implement some functionality that would convert an NDFA to a DFA.
- [X] Represent the finite automaton graphically (Optional, and can be considered as a bonus point):
- [X] Document everything in the README
- [X] Test string validation with the new more general DFA

* Results
Here's the NFA I got:
#+begin_example
Q = {q0,q1,q2,q3,q4},
∑ = {a,b},
F = {q4},
δ(q0,a) = q1,
δ(q1,b) = q1,
δ(q1,a) = q2,
δ(q2,b) = q2,
δ(q2,b) = q3,
δ(q3,b) = q4,
δ(q3,a) = q1.
#+end_example

After manually rewriting it like this:
#+begin_src python
S = {"q0","q1","q2","q3","q4"}
A = {"a","b"}
s0 = "q0"
F = {"q4"}
d = {("q0","a"): {"q1"},
     ("q1","b"): {"q1"},
     ("q1","a"): {"q2"},
     ("q2","b"): {"q2", "q3"},
     ("q3","b"): {"q4"},
     ("q3","a"): {"q1"}}
#+end_src

#+RESULTS:

I can initialize an NFA, and then do many things with it.
#+begin_src python
nfa = NFA(S=S, A=A, s0=s0, d=d, F=F)
#+end_src

#+RESULTS:

*** Convert NFA to Grammar
I can find out the type of the resulting grammar in the Chomsky hierarchy:
#+begin_src python
g = nfa.to_grammar()
print(g.type())
#+end_src

#+RESULTS:
: 3

Or print out the grammar if I format it a bit:
#+begin_src python
for l,r in g.P.items():
    print(''.join(l), '->', ' | '.join([' '.join(t) for t in r]))
#+end_src

#+RESULTS:
: q0 -> a q1
: q1 -> b q1 | a q2
: q2 -> b q2 | b q3
: q3 -> b q4 | a q1
: q4 ->
*** Find out if FA is nondeterministic
Even though it's an NFA, it could be that it doesn't have nondeterministic transitions.
We can find that out:
#+begin_src python
print(nfa.is_deterministic())
#+end_src

#+RESULTS:
: False
*** Convert NFA to DFA
#+begin_src python
dfa = nfa.to_DFA()
print(dfa)
#+end_src

#+RESULTS:
: {frozenset({'q4', 'q2', 'q3'}), frozenset({'q2'}), frozenset({'q1'}), frozenset({'q0'}), frozenset({'q2', 'q3'})}, {'a', 'b'}, {'q0'}, {(frozenset({'q0'}), 'a'): {'q1'}, (frozenset({'q1'}), 'a'): {'q2'}, (frozenset({'q1'}), 'b'): {'q1'}, (frozenset({'q2'}), 'b'): {'q2', 'q3'}, (frozenset({'q2', 'q3'}), 'a'): {'q1'}, (frozenset({'q2', 'q3'}), 'b'): {'q4', 'q2', 'q3'}, (frozenset({'q4', 'q2', 'q3'}), 'a'): {'q1'}, (frozenset({'q4', 'q2', 'q3'}), 'b'): {'q4', 'q2', 'q3'}}, {frozenset({'q4', 'q2', 'q3'})}

Now that we have a DFA, we can easily validate some strings according to the grammar.
But first, let's generate a few:
#+begin_src python
l = [g.constr_word() for _ in range(5)]
print(l)
#+end_src

#+RESULTS:
: ['aabbb', 'ababbababbbababb', 'abbbabbb', 'ababbb', 'aabbbb']

Let's verify that they're all valid:
#+begin_src python
print(all(dfa.verify(w) for w in l))
#+end_src

#+RESULTS:
: True
*** Visualize the finite automata
Here's the NFA:
#+begin_src python :results file
fn = nfa.draw('./img', 'variant_3_nfa')
print(fn)
#+end_src

#+RESULTS:
[[file:img/variant_3_nfa.gv.svg]]

And the DFA:
#+begin_src python :results file
fn = dfa.draw('./img', 'variant_3_dfa')
print(fn)
#+end_src

#+RESULTS:
[[file:img/variant_3_dfa.gv.svg]]
*** Convert Grammar to NFA to DFA (lab 1)
Extending on the previous lab task,
I can now do some things with the grammar I got:
#+begin_example
VN={S, D, R},
VT={a, b, c, d, f},
P={
    S → aS
    S → bD
    S → fR
    D → cD
    D → dR
    R → bR
    R → f
    D → d
}
#+end_example

After converting it manually to a Grammar data structure, of course:
#+begin_src python
VN = {"S", "D", "R"}
VT = {"a", "b", "c", "d", "f"}
S = "S"
P = {("S",): {("a", "S"), ("b", "D"), ("f", "R")},
     ("D",): {("c", "D"), ("d", "R"), ("d")},
     ("R",): {("b", "R"), ("f")}}
g = Grammar(VN=VN, VT=VT, P=P, S=S)
#+end_src

#+RESULTS:

Note that the keys in the =P= dict are tuples. Remember kids, =(A)= is not a tuple, but =(A,)= is.

Now, let's convert the grammar to an NFA:
#+begin_src python :results file
nfa = NFA.from_grammar(g)
print(nfa.draw('img', 'lab1_v3_nfa'))
#+end_src

#+RESULTS:
[[file:img/lab1_v3_nfa.gv.svg]]


Hmm, looks like it's not deterministic because of those two "d" transitions from the "D" state. Let's check:
#+begin_src python
print(nfa.is_deterministic())
#+end_src

#+RESULTS:
: False

Yeah, it isn't. OK, no problem. We can just convert it to a DFA:
#+begin_src python :results file
dfa = nfa.to_DFA()
print(dfa.draw('img', 'lab1_v3_dfa'))
#+end_src

#+RESULTS:
[[file:img/lab1_v3_dfa.gv.svg]]

Looks better!
* Implementation
I wrote very extensive comments inside source code files, so refer to those please.

#+begin_export markdown
### API

This part of the documentation covers all the interfaces of **angryowl**.

#### Grammar


##### _class_ angryowl.grammar.Grammar(VN: set[str], VT: set[str], P: dict[tuple[str], set[tuple[str]]], S: str)

A grammar is represented by 4 variables:


;* **Parameters**


    * **VN** – list of nonterminals (strings)


    * **VT** – list of terminals (strings)


    * **P** – list of productions represented by a dictionary, where
    keys are rules and values are sets of rules.
    A rule is a tuple of terminals and nonterminals.
    Although, a rule can also be represented by a string
    if every symbol is a single character in length.


    * **S** – starting state (string)


For example, the formal grammar:

```default
A -> aA
A -> aB
A -> ε
B -> b
```

Is represented by the following variables:

```default
VN = {"A", "B"}
VT = {"a", "b"}
P = {
    ("A",): {("a", "B"), ("a", "A"), ()},
    ("B",): {("b",)}
}
S = "A"
```


###### Rule()

alias of `tuple`[`str`]


###### constr_word()

Assuming *strictly* right-regular grammar.


;* **Returns**

    A string built using rules from the grammar picked at random.


#### Automata


##### _class_ angryowl.automata.FA(S: set[str], A: set[str], s0: str, d: dict[tuple[set[str], str], set[str]], F: set[str])

A finite automaton is represented by 5 variables.


;* **Parameters**


    * **S** – set of states (set of strings)


    * **A** – alphabet, which is a set of symbols (set of strings)


    * **s0** – starting state (a string)


    * **d** – the state-transition function (dictionary: tuple(state, symbol) -> set of states)


    * **F** – set of final states (must be subset of S)



##### _class_ angryowl.automata.NFA(S: set[str], A: set[str], s0: str, d: dict[tuple[set[str], str], set[str]], F: set[str])

Each rule in the regular grammar is treated as follows:


1. A -> aB

>
>     * a transition is created: (A, a): B


>     * “a” is added to the alphabet


2. A -> a

>
>     * a transition is created: (A, a): ε


>     * a final state is added: ε


>     * “a” is added to the alphabet


3. B -> ε

>
>     * a final state is added: B

For example, the formal grammar:

```default
A -> aA
A -> aB
A -> ε
B -> b
```

is transformed into the following NFA:

```default
S = {'B', 'ε', 'A'}
A = {'a', 'b'}
s0 = 'A'
d = {('A', 'a'): {'A', 'B'}, ('B', 'b'): {'ε'}}
F = {'ε', 'A'}
```


###### from_grammar()

This function only recognizes *strictly* regular grammars


###### to_DFA()

For an explanation of the algo, check out the dragon book.


##### _class_ angryowl.automata.DFA(S: set[str], A: set[str], s0: str, d: dict[tuple[set[str], str], set[str]], F: set[str])

This Deterministic finite automaton is similar to the NFA,
with the distinction that states are now represented by sets, and not strings.
For example, in the transitions dict,
a value is a set of states denoting a single “node” in the DFA graph,
not multiple possible states like in the case of an NFA,
whereas the keys are now represented by tuple[set[State], Symbol]
The other variables, S, s0 and F also reflect this change.

For example, the NFA:

```default
S = {'B', 'ε', 'A'}
A = {'a', 'b'}
s0 = 'A'
d = {('A', 'a'): {'A', 'B'}, ('B', 'b'): {'ε'}}
F = {'ε', 'A'}
```

is transformed into the following DFA:

```default
S = {{'A'}, {'A', 'B'}, {'ε'}}
A = {'a', 'b'}
s0 = {'A'}
d = {
    ({'A'}, 'a'): {'A', 'B'},
    ({'A', 'B'}, 'a'): {'A', 'B'},
    ({'A', 'B'}, 'b'): {'ε'}
}
F = {{'A'}, {'A', 'B'}, {'ε'}}
```

#+end_export

